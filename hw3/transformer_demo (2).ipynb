{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer for CIFAR10\n",
    "\n",
    "A configurable transformer model will be used for CIFAR10 image classification. \n",
    "\n",
    "The vision transformer model is a modified version of ViT. The changes are:\n",
    "1) No position embedding.\n",
    "2) No dropout is used.\n",
    "3) All encoder features are used for class prediction.\n",
    "\n",
    "The code below is a simplified version of Timm modules.\n",
    "\n",
    "Let us import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchmetrics.functional import accuracy\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torchvision.datasets.cifar import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Module\n",
    "\n",
    "The `Attention` module is the core of the vision transformer model. It implements the attention mechanism:\n",
    "\n",
    "1) Multiply QKV by their weights\n",
    "2) Perform dot product on Q and K. \n",
    "3) Normalize the result in 2) by sqrt of `head_dim`  \n",
    "4) Softmax is applied to the result.\n",
    "5) Perform dot product on the result of 4) and V and the result is the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, 'dim should be divisible by num_heads'\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Module\n",
    "\n",
    "The MLP module is a made of two linear layers. A non-linear activation is applied to the output of the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "      \n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Block Module\n",
    "\n",
    "The `Block` module represents one encoder transformer block. It consists of two sub-modules:\n",
    "1) The Attention module\n",
    "2) The MLP module\n",
    "\n",
    "Layer norm is applied before and after the Attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self, dim, num_heads, mlp_ratio=4., qkv_bias=False, \n",
    "            act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias) \n",
    "        self.norm2 = norm_layer(dim)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio), act_layer=act_layer) \n",
    "   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Transformer Module\n",
    "\n",
    "The feature encoder is made of several transformer blocks. The most important attributes are:\n",
    "1) `depth` : representing the number of encoder blocks\n",
    "2) `num_heads` : representing the number of attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_blocks, mlp_ratio=4., qkv_bias=False,  \n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([Block(dim, num_heads, mlp_ratio, qkv_bias, \n",
    "                                     act_layer, norm_layer) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optional parameter initialization as adopted from `timm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_vit_timm(module: nn.Module):\n",
    "    \"\"\" ViT weight initialization, original timm impl (for reproducibility) \"\"\"\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.trunc_normal_(module.weight, mean=0.0, std=0.02)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "    elif hasattr(module, 'init_weights'):\n",
    "        module.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Lightning for CIFAR10 Image Classification\n",
    "\n",
    "We use the `Transformer` module to build the feature encoder. Before the `Transformer` can be used, we convert the input image into patches. The patches are then embedded into a linear space. The output is then passed to the Transformer.\n",
    "\n",
    "Another difference between this model is we use all output features for the final classification. In the ViT, only the first feature is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LitTransformer(LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=0.001, max_epochs=30, depth=12, embed_dim=64,\n",
    "                 head=4, patch_dim=192, seqlen=16, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = Transformer(dim=embed_dim, num_heads=head, num_blocks=depth, mlp_ratio=4.,\n",
    "                                   qkv_bias=False, act_layer=nn.GELU, norm_layer=nn.LayerNorm)\n",
    "        self.embed = torch.nn.Linear(patch_dim, embed_dim)\n",
    "\n",
    "        self.fc = nn.Linear(seqlen * embed_dim, num_classes)\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init_weights_vit_timm(self)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear projection\n",
    "        x = self.embed(x)\n",
    "            \n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        # Classification head\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        # this decays the learning rate to 0 after max_epochs using cosine annealing\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        return {\"y_hat\": y_hat, \"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        self.log(\"test_loss\", avg_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", avg_acc*100., on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.test_step(batch, batch_idx)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.test_epoch_end(outputs)\n",
    "\n",
    "\n",
    "# a lightning data module for cifar 10 dataset\n",
    "class LitCifar10(LightningDataModule):\n",
    "    def __init__(self, batch_size=32, num_workers=32, patch_num=4, **kwargs):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_num = patch_num\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_set = CIFAR10(root='./data', train=True,\n",
    "                                 download=True, transform=torchvision.transforms.ToTensor())\n",
    "        self.test_set = CIFAR10(root='./data', train=False,\n",
    "                                download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        x, y = zip(*batch)\n",
    "        x = torch.stack(x, dim=0)\n",
    "        y = torch.LongTensor(y)\n",
    "        x = rearrange(x, 'b c (p1 h) (p2 w) -> b (p1 p2) (c h w)', p1=self.patch_num, p2=self.patch_num)\n",
    "        return x, y\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, \n",
    "                                        shuffle=True, collate_fn=self.collate_fn,\n",
    "                                        num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_set, batch_size=self.batch_size, \n",
    "                                        shuffle=False, collate_fn=self.collate_fn,\n",
    "                                        num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.test_dataloader()\n",
    "\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = ArgumentParser(description='PyTorch Transformer')\n",
    "    parser.add_argument('--depth', type=int, default=12, help='depth')\n",
    "    parser.add_argument('--embed_dim', type=int, default=64, help='embedding dimension')\n",
    "    parser.add_argument('--num_heads', type=int, default=4, help='num_heads')\n",
    "\n",
    "    parser.add_argument('--patch_num', type=int, default=8, help='patch_num')\n",
    "    parser.add_argument('--kernel_size', type=int, default=3, help='kernel size')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: )')\n",
    "    parser.add_argument('--max-epochs', type=int, default=30, metavar='N',\n",
    "                        help='number of epochs to train (default: 0)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.0)')\n",
    "\n",
    "    parser.add_argument('--accelerator', default='gpu', type=str, metavar='N')\n",
    "    parser.add_argument('--devices', default=1, type=int, metavar='N')\n",
    "    parser.add_argument('--dataset', default='cifar10', type=str, metavar='N')\n",
    "    parser.add_argument('--num_workers', default=4, type=int, metavar='N')\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on different settings\n",
    "\n",
    "The following table shows different performances on different settings. Generally, Transformer is better than MLP in terms of accuracy and parameter count. However, the performance is worse compared to CNN models. \n",
    "\n",
    "However, the most important thing to note is that Transformers are more general purpose models than CNNs. They can process different types of data. They can process multiple types of data at the same time. This is why they are considered to be the backbone of many high-performing models like BERT, GPT3, PalM and Gato.\n",
    "\n",
    "| **Depth** | **Head** | **Embed dim** | **Patch size** | **Seq len** | **Params** | **Accuracy** | \n",
    "| -: | -: | -: | -: | -: | -: | -: |\n",
    "| 12 | 4 | 32 | 4x4 | 64 | 173k | 68.2% |\n",
    "| 12 | 4 | 64 | 4x4 | 64 | 641k | 71.1% |\n",
    "| 12 | 4 | 128 | 4x4 | 64 | 2.5M | 71.5% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Embed dim: 64\n",
      "Patch size: 4\n",
      "Sequence length: 64\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo (2).ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSequence length:\u001b[39m\u001b[39m\"\u001b[39m, seqlen)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=16'>17</a>\u001b[0m model \u001b[39m=\u001b[39m LitTransformer(num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, lr\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mlr, epochs\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mmax_epochs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=17'>18</a>\u001b[0m                        depth\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mdepth, embed_dim\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39membed_dim, head\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=18'>19</a>\u001b[0m                        patch_dim\u001b[39m=\u001b[39mpatch_dim, seqlen\u001b[39m=\u001b[39mseqlen,)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=20'>21</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(accelerator\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49maccelerator, devices\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mdevices,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=21'>22</a>\u001b[0m                   max_epochs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mmax_epochs, precision\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m \u001b[39mif\u001b[39;49;00m args\u001b[39m.\u001b[39;49maccelerator \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m32\u001b[39;49m,)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dl/Desktop/dl/object_detection_model_hw2/hw3/transformer_demo%20%282%29.ipynb#ch0000015?line=22'>23</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, datamodule\u001b[39m=\u001b[39mdatamodule)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py?line=335'>336</a>\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py?line=337'>338</a>\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py?line=338'>339</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:483\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=479'>480</a>\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=480'>481</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=482'>483</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=483'>484</a>\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=484'>485</a>\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=485'>486</a>\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=486'>487</a>\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=487'>488</a>\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=488'>489</a>\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=489'>490</a>\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=490'>491</a>\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=491'>492</a>\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=492'>493</a>\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=493'>494</a>\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=494'>495</a>\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=495'>496</a>\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=496'>497</a>\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=497'>498</a>\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=498'>499</a>\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=499'>500</a>\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=500'>501</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=501'>502</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=502'>503</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:196\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=193'>194</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=194'>195</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_accelerator()\n\u001b[0;32m--> <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=195'>196</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=197'>198</a>\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=198'>199</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:514\u001b[0m, in \u001b[0;36mAcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=509'>510</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=510'>511</a>\u001b[0m     available_accelerator \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=511'>512</a>\u001b[0m         acc_str \u001b[39mfor\u001b[39;00m acc_str \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_types \u001b[39mif\u001b[39;00m AcceleratorRegistry\u001b[39m.\u001b[39mget(acc_str)\u001b[39m.\u001b[39mis_available()\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=512'>513</a>\u001b[0m     ]\n\u001b[0;32m--> <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=513'>514</a>\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=514'>515</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=515'>516</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=516'>517</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=517'>518</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=518'>519</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=520'>521</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[1;32m    <a href='file:///home/dl/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py?line=522'>523</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "\n",
    "    datamodule = LitCifar10(batch_size=args.batch_size,\n",
    "                            patch_num=args.patch_num, \n",
    "                            num_workers=args.num_workers * args.devices)\n",
    "    datamodule.prepare_data()\n",
    "\n",
    "    data = iter(datamodule.train_dataloader()).next()\n",
    "    patch_dim = data[0].shape[-1]\n",
    "    seqlen = data[0].shape[-2]\n",
    "    print(\"Embed dim:\", args.embed_dim)\n",
    "    print(\"Patch size:\", 32 // args.patch_num)\n",
    "    print(\"Sequence length:\", seqlen)\n",
    "\n",
    "\n",
    "    model = LitTransformer(num_classes=10, lr=args.lr, epochs=args.max_epochs, \n",
    "                           depth=args.depth, embed_dim=args.embed_dim, head=args.num_heads,\n",
    "                           patch_dim=patch_dim, seqlen=seqlen,)\n",
    "\n",
    "    trainer = Trainer(accelerator=args.accelerator, devices=args.devices,\n",
    "                      max_epochs=args.max_epochs, precision=16 if args.accelerator == 'gpu' else 32,)\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
